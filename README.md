# ğŸ’Š PrÃ©diction des coÃ»ts mÃ©dicaux 
### *Machine Learning â€“ Analyse, ModÃ©lisation & DÃ©ploiement*

Ce projet vise Ã  **prÃ©dire les dÃ©penses mÃ©dicales annuelles** Ã  partir de caractÃ©ristiques socio-dÃ©mographiques, en mobilisant des **mÃ©thodes de Machine Learning**.

---
## Objectifs
- Comparer **modÃ¨les linÃ©aires, non linÃ©aires et ensemblistes**
- Ã‰valuer lâ€™impact :
  - de la transformation logarithmique de la cible,
  - du prÃ©traitement des variables catÃ©gorielles,
  - des stratÃ©gies de rÃ©gularisation
- SÃ©lectionner les **meilleurs modÃ¨les prÃ©dictifs**
- DÃ©ployer une **API de prÃ©diction** et une **interface web utilisateur**
- Fournir une **documentation technique complÃ¨te** (Bookdown)

---
## Livrables

### Documentation technique (Bookdown)  
https://sarahlaure.github.io/Analyse_Assurance_Sante/

### Canva
Support de prÃ©sentation

### API de prÃ©diction
https://ml-medical-coasts-kz1m.onrender.com

### Interface web
https://comforting-sherbet-b5f901.netlify.app/

---
## DonnÃ©es utilisÃ©es

- **Source** : Kaggle â€“ *Medical Cost Personal Dataset*
- **Observations** : 1 338 individus
- **Variable cible** :
  - `charges` : dÃ©penses mÃ©dicales annuelles (USD)

### Variables explicatives

| Type | Variables |
|----|----|
| NumÃ©riques | `age`, `bmi`, `children` |
| CatÃ©gorielles | `sex`, `smoker`, `region` |

Une vÃ©rification systÃ©matique de la qualitÃ© des donnÃ©es a Ã©tÃ© rÃ©alisÃ©e :
- **aucune valeur manquante** nâ€™a Ã©tÃ© dÃ©tectÃ©e ;
- **un doublon exact** a Ã©tÃ© identifiÃ© et supprimÃ© par prÃ©caution

## Structure du dÃ©pÃ´t

```text
ML_medical-coasts/
â”œâ”€â”€ API/
â”‚   â”œâ”€â”€ app.py              # Application FastAPI (moteur de prÃ©diction)
â”‚   â”œâ”€â”€ requirements.txt    # DÃ©pendances pour le dÃ©ploiement Render
â”‚   â””â”€â”€ best_pipeline.pkl           # Meilleur modÃ¨le CatBoost sÃ©rialisÃ©
â”œâ”€â”€ EDA/
â”‚   â”œâ”€â”€ EDA.ipynb           # Notebook d'analyse exploratoire
â”‚   â””â”€â”€ figures/            # Graphiques exportÃ©s
â”œâ”€â”€ ModÃ©lisation/
â”‚   â”œâ”€â”€ modelisation.ipynb # ModÃ¨les linÃ©aires et diagnostics + KNN, SVR, Arbres + ModÃ¨les de boosting et forÃªts alÃ©atoires
â”œâ”€â”€ Power point/
â”‚   â””â”€â”€ presentation_canva.pdf   # Support de prÃ©sentation
â”œâ”€â”€ docs/ (Site Web - GitHub Pages)
â”‚   â”œâ”€â”€ index.html          # Page d'accueil du site
â”‚   â”œâ”€â”€ EDA.html            # Rapport d'analyse exploratoire
â”‚   â”œâ”€â”€ ModÃ¨les.html        # Rapport de modÃ©lisation
â”‚   â”œâ”€â”€ PrÃ©diction.html     # Interface des rÃ©sultats
â”‚   â”œâ”€â”€ CSS/ & JS/          # Ressources de mise en forme et scripts
â”‚   â””â”€â”€ Plot/Eda/           # Visualisations interactives du site
â”œâ”€â”€ README.md               # Documentation principale
```

## MÃ©thodologie gÃ©nÃ©rale

### Analyse exploratoire (EDA)
- Analyses univariÃ©es et bivariÃ©es
- Ã‰tude des distributions et de lâ€™asymÃ©trie
- Visualisations : histogrammes, boxplots, scatterplots
- Test statistique de Mannâ€“Whitney (statut tabagique)
- Justification de la transformation `log(1 + charges)`

### PrÃ©traitement
- Split **Train / Test : 80 % / 20 %**
- Pipelines `scikit-learn` (anti data leakage)
- One-Hot Encoding des variables catÃ©gorielles
- Mise Ã  lâ€™Ã©chelle optionnelle des variables numÃ©riques
- Transformations apprises uniquement sur *train*

### ModÃ©lisation
Deux stratÃ©gies comparÃ©es :
- prÃ©diction directe de `charges`
- prÃ©diction de `log(1 + charges)` avec retransformation
HyperparamÃ¨tres optimisÃ©s via **GridSearchCV (CV = 5)**

### Ã‰valuation
MÃ©triques reportÃ©es sur *train* et *test* :
- **RMSE** (*Root Mean Squared Error*)__ MÃ©trique principale
- **MSE** (*Mean Squared Error*)  
- **MAE** (*Mean Absolute Error*)  
- **\(R^2\)** (*coefficient de dÃ©termination*)  
- **MAPE** (*Mean Absolute Percentage Error*)

--- 

## ModÃ¨les implÃ©mentÃ©s

### ModÃ¨les LinÃ©aires & Diagnostics
Une famille de modÃ¨les de rÃ©fÃ©rence a Ã©tÃ© testÃ©e (**OLS**, **Ridge**, **Lasso**, **Elastic Net**) avec un contrÃ´le strict de la validitÃ© statistique :
* VÃ©rification de la **normalitÃ©** et de l'**homoscÃ©dasticitÃ©** des rÃ©sidus.
* ContrÃ´le de la **multicolinÃ©aritÃ©** via le calcul du **VIF** (Variance Inflation Factor).

### Algorithmes Non LinÃ©aires
Pour capturer des relations complexes, nous avons explorÃ© des approches basÃ©es sur la proximitÃ© et les structures d'arbres :
* **K-Nearest Neighbors (KNN)** et **SVR**.
* **Arbres de dÃ©cision**.

### MÃ©thodes Ensemblistes (Performances Optimales)
Ces modÃ¨les ont offert les meilleurs rÃ©sultats grÃ¢ce Ã  la combinaison d'estimateurs :
* **Bagging** : Random Forest.
* **Boosting** : AdaBoost, Gradient Boosting et les variantes de pointe (**XGBoost**, **LightGBM**, **CatBoost**).

## RÃ©sultats clÃ©s
Meilleur performance globale sur CatBoost sur la cible charges

## Cloner le projet
git clone https://github.com/nncelina/ML_medical-coasts.git

## Installer les dÃ©pendances
pip install -r requirements.txt

---
## ğŸ‘¥ Auteurs
* **DIALLO** Cheick Oumar
* **FALL** Ndeye Ramatoulaye Ndoye
* **FOGWOUNG DJOUFACK** Sarah-Laure
* **NGUEMFOUO NGOUMTSA** CÃ©lina
* **RASAMOELINA** Nihaviana Albert Paulinah,
Ã‰lÃ¨ves ingÃ©nieurs statisticiens Ã©conomistes (ISE 2), ENSAE

---
*Sous la supervision de Mme Mously DIAW, Freelance Senior Data Scientist / ML Engineer*
